{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cogs 118C, Spring 2020\n",
    "\n",
    "\n",
    "## HW7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Malachi Mabie\n",
    "\n",
    "Student ID: A15737533"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Entropy w regard to visual stimulus action potential relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy of unbiased die =  2.584962500721156\n"
     ]
    }
   ],
   "source": [
    "# a) What is the entropy for the outcome of rolling a standard six-side die?\n",
    "# P(x)= 1/6 for all x. Therefore,\n",
    "entropy = -(6/6)*(np.log2(1/6))\n",
    "print(\"entropy of unbiased die = \", entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy of single nucelotide position =  1.8812908992306927\n"
     ]
    }
   ],
   "source": [
    "# b) The frequency of each of the 4 nucleotides (A,C,G,T) in mammalian genomes is roughly:\n",
    "#    P(A) = P(T) = .35; P(G) = P(C) = .15\n",
    "# What is the entropy of a single nucelotide position in the genome?\n",
    "\n",
    "entropy = -2*(.35)*np.log2(.35) - 2*(.15)*np.log2(.15)\n",
    "print(\"entropy of single nucelotide position = \", entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joint entropy of two standard dice =  4.136636511405688\n"
     ]
    }
   ],
   "source": [
    "# c) Suppose I roll two standard dice, and let x1 and x2 be the outcomes of each roll.\n",
    "#    What is the joint entropy, H(x1,x2)?\n",
    "\n",
    "# freq per value is 1,2,3,4,5,6,5,4,3,2,1\n",
    "entropy = (-2*(1/6)*np.log2(1/6) - 2*(2/6)*np.log2(2/6) - 2*(3/6)*np.log2(3/6) \n",
    "- 2*(4/6)*np.log2(4/6) - 2*(5/6)*np.log2(5/6) - np.log2(1))\n",
    "\n",
    "print(\"joint entropy of two standard dice = \", entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Two rvs (X,Y) are indep if P(x,y)=P(x)P(y). Show that if x and y are independent then H(X,Y)=H(X)+H(Y) and therefore I(X;Y)=0.\n",
    "    If P(x) and P(y) are independent, then their distributions are independent.\n",
    "    Since entropy sums over all possible values of x and y, the calculation will be the same\n",
    "    whether using separated or joint entropy calculation:\n",
    "\n",
    "$$\n",
    "H(X,Y) = \\sum_{x,y} P(x,y) log_2{P(x,y)} = \\sum_{x,y} P(x)P(y) log_2{(P(x)P(y))}\n",
    "$$\n",
    "$$\n",
    " = \\sum_{x,y} P(x)P(y) log_2{P(x)} log_2{P(y)} = \\sum_{x} P(x) log_2{P(x)} + \\sum_{y} P(y) log_2{P(y)}\n",
    "$$\n",
    "$$\n",
    " = H(X) + H(Y)\n",
    "$$\n",
    "\n",
    "    Mutual information between two random variables is defined as:\n",
    "$$\n",
    "I(X;Y)=H(X)+H(Y)-H(X,Y)\n",
    "$$\n",
    "\n",
    "    Which with independence becomes\n",
    "$$\n",
    "H(X)+H(Y) - (H(X)+H(Y)) = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e) What is the joint entropy for N dice rolls? Using this definition:\n",
    "$$\n",
    "H(x_1,x_2,...,x_N) = -\\sum_{x_1} \\sum_{x_2} ... \\sum_{x_N} P(x_1, ... , x_N) log_2{P(x_1,...,x_N)}\n",
    "$$\n",
    "\n",
    "    Since the dice rolls are all independent random variables:\n",
    "$$\n",
    "P(x_1, ... , x_N) = P(x_1)P(x_2)...P(x_N)\n",
    "$$\n",
    "\n",
    "    Using our findings from part (d):\n",
    "$$\n",
    "H(x_1,x_2,...,x_N) = -\\sum_{x_1} P(x_1) log_2{P(x_1)} - ...  -\\sum_{x_N} P(x_N) log_2{P(x_N)} = H(x_1) + ... + H(x_N)\n",
    "$$\n",
    "\n",
    "    Incorporating the data in qustion (dice entropy), where N dice rolls is represented by X_N:\n",
    "$$\n",
    "H(X_N) = -N * log_2{1/6}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fragment</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TH</td>\n",
       "      <td>116997844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HE</td>\n",
       "      <td>100689263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IN</td>\n",
       "      <td>87674002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ER</td>\n",
       "      <td>77134382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AN</td>\n",
       "      <td>69775179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fragment  frequency\n",
       "0       TH  116997844\n",
       "1       HE  100689263\n",
       "2       IN   87674002\n",
       "3       ER   77134382\n",
       "4       AN   69775179"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fragment</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E</td>\n",
       "      <td>529117365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T</td>\n",
       "      <td>390965105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>374061888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O</td>\n",
       "      <td>326627740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>320410057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fragment  frequency\n",
       "0        E  529117365\n",
       "1        T  390965105\n",
       "2        A  374061888\n",
       "3        O  326627740\n",
       "4        I  320410057"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fragment</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>THE</td>\n",
       "      <td>58784490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OF</td>\n",
       "      <td>25242547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AND</td>\n",
       "      <td>25188846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TO</td>\n",
       "      <td>24462483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>22290078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fragment  frequency\n",
       "0      THE   58784490\n",
       "1       OF   25242547\n",
       "2      AND   25188846\n",
       "3       TO   24462483\n",
       "4        A   22290078"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# f) Download the table of single letter (monogram) and 2-letter (bigram) frequencies for English,\n",
    "#    as well as a list of common English words, from source. Compute the entropy per letter for English text.\n",
    "#    Make sure to normalize to get the probability of each letter.\n",
    "\n",
    "bigrams = pd.read_csv(\"english_bigrams_1.txt\",sep=\" \", keep_default_na=False, na_values=['_'], header=None)\n",
    "bigrams.columns = [\"fragment\", \"frequency\"]\n",
    "bigrams.astype({\"fragment\":\"str\"})\n",
    "display(bigrams.head())\n",
    "\n",
    "monograms = pd.read_csv(\"english_monograms.txt\",sep=\" \", keep_default_na=False, na_values=['_'], header=None)\n",
    "monograms.columns = [\"fragment\", \"frequency\"]\n",
    "monograms.astype({\"fragment\":\"str\"})\n",
    "display(monograms.head())\n",
    "\n",
    "words = pd.read_csv(\"english_words.txt\",sep=\" \", keep_default_na=False, na_values=['_'], header=None)\n",
    "words.columns = [\"fragment\", \"frequency\"]\n",
    "words.astype({\"fragment\":\"str\"})\n",
    "display(words.head())\n",
    "\n",
    "# the letter combinations may be assumed to be independent.\n",
    "data = monograms.append(bigrams.append(words))#.drop_duplicates(keep='last',inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy per letter, from monograms =  4.1846008280191365\n"
     ]
    }
   ],
   "source": [
    "# entropy calculations:\n",
    "def entropy_calc(data):\n",
    "    alphabet = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "    entropies = []\n",
    "    for letter in alphabet:\n",
    "        l_freq = 0\n",
    "        for fragment,frequency in data.itertuples(index=False):\n",
    "            if(isinstance(fragment, str)):\n",
    "                if(letter in fragment):\n",
    "                    l_freq += frequency\n",
    "            elif(letter==\"A\"):\n",
    "                print(fragment,frequency)\n",
    "        entropies.append(l_freq)\n",
    "    entropies = pd.DataFrame(entropies)\n",
    "    entropies = entropies / data.frequency.sum() # normalize\n",
    "    entropies = -1 * entropies * np.log2(entropies) # calculate\n",
    "    total_entropy = entropies.sum().loc[0] # total\n",
    "    return(total_entropy)\n",
    "monogram_entropy = entropy_calc(monograms)\n",
    "print(\"entropy per letter, from monograms = \", monogram_entropy)\n",
    "\n",
    "# print(\"entropy per letter from bigrams = \", entropy_calc(bigrams)) # 6.3151598262078465\n",
    "# print(\"entropy per letter from words = \", entropy_calc(words)) # 9.061705244835611\n",
    "# print(\"entropy per letter from all sources = \", entropy_calc(data)) # 5.913644745465774"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy of the distribution of random text bigrams =  8.369201656038273\n"
     ]
    }
   ],
   "source": [
    "# g) Now imagine a randomly generated “text” with these letter frequencies.\n",
    "#    That is, assume that every letter is independent of the other letters.\n",
    "#    What is the entropy of the distribution of 2-letter bigrams in this random text?\n",
    "\n",
    "# using the given monogram frequencies, and under the independent combination suggestion:\n",
    "bigram_from_monogram_entropy = 2 * monogram_entropy # custom distribution\n",
    "print(\"entropy of the distribution of random text bigrams = \", bigram_from_monogram_entropy)\n",
    "\n",
    "# # Because each letter in the bigram is independent, we can treat this like the dice problem.\n",
    "# indep_bigram_entropy = -2 * np.log2(1/26) # uniform distribution\n",
    "# print(\"entropy of a randomly generated bigram = \", indep_bigram_entropy) # 9.400879436282183\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Letter combo</th>\n",
       "      <th>Probability from letter freq</th>\n",
       "      <th>Probability from bigram freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QU</td>\n",
       "      <td>0.00077773</td>\n",
       "      <td>0.00096422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TH</td>\n",
       "      <td>0.12349581</td>\n",
       "      <td>0.02705698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HT</td>\n",
       "      <td>0.12349581</td>\n",
       "      <td>0.00193138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UQ</td>\n",
       "      <td>0.00077773</td>\n",
       "      <td>0.00000541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Letter combo Probability from letter freq Probability from bigram freq\n",
       "0           QU                   0.00077773                   0.00096422\n",
       "1           TH                   0.12349581                   0.02705698\n",
       "2           HT                   0.12349581                   0.00193138\n",
       "3           UQ                   0.00077773                   0.00000541"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# h) If you analyzed a randomly generated “text” with these letter frequencies,\n",
    "#    what would be the probability of the letter combinations “QU” and “TH” ?\n",
    "#    How about “HT” and “UQ”?  Compare these with the actual frequencies in English.\n",
    "\n",
    "normal = monograms[\"frequency\"].sum()\n",
    "\n",
    "letter_combo_prob = pd.DataFrame(columns=[\"Letter combo\", \"Probability from letter freq\", \"Probability from bigram freq\"],\n",
    "                                index=[0,1,2,3])\n",
    "\n",
    "letter_combo_prob.loc[0] =[\"QU\", \"{:.8f}\".format((monograms[monograms[\"fragment\"]==\"Q\"][\"frequency\"].values[0]\n",
    "                                             * monograms[monograms[\"fragment\"]==\"U\"][\"frequency\"].values[0]) / normal**2),\n",
    "                     \"{:.8f}\".format(bigrams[bigrams[\"fragment\"]==\"QU\"][\"frequency\"].values[0] / bigrams[\"frequency\"].sum())]\n",
    "\n",
    "letter_combo_prob.loc[1] =[\"TH\", \"{:.8f}\".format((monograms[monograms[\"fragment\"]==\"T\"][\"frequency\"].values[0] \n",
    "                                             * monograms[monograms[\"fragment\"]==\"H\"][\"frequency\"].values[0]) / normal**2),\n",
    "                    \"{:.8f}\".format(bigrams[bigrams[\"fragment\"]==\"TH\"][\"frequency\"].values[0] / bigrams[\"frequency\"].sum())]\n",
    "\n",
    "letter_combo_prob.loc[2] =[\"HT\", \"{:.8f}\".format((monograms[monograms[\"fragment\"]==\"T\"][\"frequency\"].values[0]\n",
    "                                             * monograms[monograms[\"fragment\"]==\"H\"][\"frequency\"].values[0]) / normal**2),\n",
    "                     \"{:.8f}\".format(bigrams[bigrams[\"fragment\"]==\"HT\"][\"frequency\"].values[0] / bigrams[\"frequency\"].sum())]\n",
    "\n",
    "letter_combo_prob.loc[3] =[\"UQ\", \"{:.8f}\".format((monograms[monograms[\"fragment\"]==\"Q\"][\"frequency\"].values[0]\n",
    "                                             * monograms[monograms[\"fragment\"]==\"U\"][\"frequency\"].values[0]) / normal**2),\n",
    "                      \"{:.8f}\".format(bigrams[bigrams[\"fragment\"]==\"UQ\"][\"frequency\"].values[0] / bigrams[\"frequency\"].sum())]\n",
    "\n",
    "display(letter_combo_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy per letter from bigrams: 6.3151598262078465\n",
      "entropy from 1g  prediction:\t 8.369201656038273\n"
     ]
    }
   ],
   "source": [
    "# i) Using the actual frequency of 2-letter bigrams in English, compute the entropy per bigram.\n",
    "#    Compare this with your theoretical prediction (1g, above): Is it larger or smaller, and why?\n",
    "print(\"entropy per letter from bigrams:\", entropy_calc(bigrams))\n",
    "print(\"entropy from 1g  prediction:\\t\", bigram_from_monogram_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    The actual entropy is less than the predicted entropy because the prediction supposes independence, \n",
    "    while in actuality there exists structure (grammar, vocab, usage norms) that reduces entropy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### j) Combine the previous results to compute the mutual information between the first and second letters in an English bigram.\n",
    "$$\n",
    "I(A;B) = H(A) + H(B) - H(A,B) = 2H(A) - H(A,B)\n",
    "$$\n",
    "$$\n",
    " = (8.369 - 6.315) = 2.054\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Frequency</th>\n",
       "      <th>Predicted Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NEURON</th>\n",
       "      <td>858</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UCSD</th>\n",
       "      <td>422</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual Frequency Predicted Frequency\n",
       "NEURON              858                  72\n",
       "UCSD                422                2013"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# k) Compute the actual and predicted frequencies of the words “NEURON” and “UCSD,”\n",
    "#    and compare these with the prediction based on the independent letters model.\n",
    "normal = words[\"frequency\"].sum()\n",
    "\n",
    "word_freqs = pd.DataFrame(columns=[\"Actual Frequency\", \"Predicted Frequency\"],index=[\"NEURON\",\"UCSD\"])\n",
    "word_freqs.loc[\"NEURON\"][\"Actual Frequency\"] = words[words[\"fragment\"]==\"NEURON\"][\"frequency\"].values[0]\n",
    "word_freqs.loc[\"UCSD\"][\"Actual Frequency\"] = words[words[\"fragment\"]==\"UCSD\"][\"frequency\"].values[0]\n",
    "\n",
    "def letter_prob(word):\n",
    "    s = monograms[\"frequency\"].sum()\n",
    "    prob = 1\n",
    "    for letter in word:\n",
    "        prob *= monograms[monograms[\"fragment\"]==letter][\"frequency\"].values[0]/s\n",
    "    return prob \n",
    "\n",
    "word_freqs.loc[\"NEURON\"][\"Predicted Frequency\"] = (normal*letter_prob(\"NEURON\")).round()\n",
    "word_freqs.loc[\"UCSD\"][\"Predicted Frequency\"] = (normal*letter_prob(\"UCSD\")).round()\n",
    "\n",
    "display(word_freqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the log likelihood ratio, where h0 is the independent letters model and h1 is the model using the actual frequencies of English words?\n",
    "$$\n",
    "log{[P(w | h_1) / P(w | h_0)]} = log{P(w|h_1)} - log{P(w|h_0)}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Frequency</th>\n",
       "      <th>Predicted Frequency</th>\n",
       "      <th>Likelihood Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NEURON</th>\n",
       "      <td>858</td>\n",
       "      <td>72</td>\n",
       "      <td>2.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UCSD</th>\n",
       "      <td>422</td>\n",
       "      <td>2013</td>\n",
       "      <td>-1.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual Frequency Predicted Frequency Likelihood Ratio\n",
       "NEURON              858                  72             2.48\n",
       "UCSD                422                2013            -1.56"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculating this ratio for the words given:\n",
    "word_freqs[\"Likelihood Ratio\"] = [\"{:.2f}\".format(np.log(858/72)), \"{:.2f}\".format(np.log(422/2013))]\n",
    "display(word_freqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Poisson Spiking problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a (very simplified) Poisson spiking model of a retinal ganglion cell. The cell produces spikes at rate r_1=4 Hz when stimulus 1 is presented (e.g. a bright spot), and it spikes at rate r_2=1 Hz when stimulus 2 (a dark spot) is presented. Let X be the random variable describing the stimulus, and P(x=1)=P(x=2)=1/2. Let n{0,1} be the number of spikes emitted by the cell during a time interval of duration dt =10 ms following stimulus presentation. In this problem we will neglect the small probability of >1 spike occurring in a given time bin, so that\n",
    "$$P(n=1|x=1)=r_1 dt=0.04$$\n",
    "$$P(n=1|x=2)=r_2 dt=0.01$$\n",
    "$$P(n=0|x)=1-P(n=1|x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Compute P(n = 1). This is the marginal probability for n.\n",
    "$$P(n)=P(n|x=1)P(x=1)+P(n|x=2)P(x=2)=\\frac{1}{2}[P(n|x=1)+P(n|x=2)]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marginal Probability P(n) =  0.025\n"
     ]
    }
   ],
   "source": [
    "# a)\n",
    "p = .5 # P(x)\n",
    "x1 = 4*.01 # P(1|x1)\n",
    "x2 = 1*.01 # P(1|x2)\n",
    "n = (x1+x2)*p # P(n)\n",
    "print(\"Marginal Probability P(n) = \", n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x=1</th>\n",
       "      <th>x=2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n=0</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n=1</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      x=1    x=2\n",
       "n=0  0.48  0.495\n",
       "n=1  0.02  0.005"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# b) Define the joint distribution, P(x,n)=P(n|x)P(x). Make a 2x2 table showing the joint probability.\n",
    "_x1 = 1 - x1 # P(0|x1)\n",
    "_x2 = 1 - x2 # P(0|x2)\n",
    "_n = 1 - n\n",
    "joint_dist = pd.DataFrame(columns=[\"x=1\", \"x=2\"],index=[\"n=0\",\"n=1\"])\n",
    "joint_dist.loc[\"n=0\"] = [_x1, _x2]\n",
    "joint_dist.loc[\"n=1\"] = [x1, x2]\n",
    "joint_dist = joint_dist*p\n",
    "\n",
    "display(joint_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>H(x)</th>\n",
       "      <th>H(n)</th>\n",
       "      <th>H(x,n)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.168661</td>\n",
       "      <td>1.186543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   H(x)      H(n)    H(x,n)\n",
       "0   1.0  0.168661  1.186543"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# c) What are H(x), H(n), and H(x,n)?\n",
    "\n",
    "Hx = -np.log2(p)\n",
    "Hn = -n*np.log2(n) - _n*np.log2(_n)\n",
    "Hxn = joint_dist.applymap(np.log2)\n",
    "Hxn = Hxn * -joint_dist\n",
    "Hxn = Hxn_12.sum().sum()\n",
    "entropy = pd.DataFrame(columns=[\"H(x)\", \"H(n)\", \"H(x,n)\"])\n",
    "entropy.loc[0] = [Hx,Hn,Hxn]\n",
    "display(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mutual information I(x;n):  -0.017881730992492573\n"
     ]
    }
   ],
   "source": [
    "# d) What is the mutual information I(x;n)?\n",
    "#    (This is the “number of bits of information” that the neuron’s spike rate carries about the stimulus.)\n",
    "mutual_info = (entropy[\"H(x)\"]+entropy[\"H(n)\"]-entropy[\"H(x,n)\"])[0]\n",
    "print(\"mutual information I(x;n): \", mutual_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x=1</th>\n",
       "      <th>x=2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n=00</th>\n",
       "      <td>0.479816</td>\n",
       "      <td>0.494988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n=01</th>\n",
       "      <td>0.00999216</td>\n",
       "      <td>0.00249988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n=10</th>\n",
       "      <td>0.00999216</td>\n",
       "      <td>0.00249988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n=11</th>\n",
       "      <td>0.000199923</td>\n",
       "      <td>1.24997e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              x=1          x=2\n",
       "n=00     0.479816     0.494988\n",
       "n=01   0.00999216   0.00249988\n",
       "n=10   0.00999216   0.00249988\n",
       "n=11  0.000199923  1.24997e-05"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H(x,n_12) =  1.18919555082807\n"
     ]
    }
   ],
   "source": [
    "# e) time bin split in half.\n",
    "#    There are four possible outcomes: n12=[0 0] (no spikes), n12=[0 1] or n12=[1 0] (one spike), or n12=[1 1] (2 spikes).\n",
    "#    What is the joint distribution, P(x,n_12) and corresponding entropy, H(x,n_12)?\n",
    "x1 = 4*.005\n",
    "x2 = 1*.005\n",
    "_x1=1-x1**2\n",
    "_x2=1-x2**2\n",
    "__x1 = 1 - 2*x1\n",
    "__x2 = 1 - 2*x2\n",
    "\n",
    "joint_dist = pd.DataFrame(columns=[\"x=1\", \"x=2\"],index=[\"n=00\",\"n=01\",\"n=10\",\"n=11\"])\n",
    "joint_dist.loc[\"n=00\"] = [__x1, __x2]\n",
    "joint_dist.loc[\"n=01\"] = [x1*_x1, x2*_x2]\n",
    "joint_dist.loc[\"n=10\"] = joint_dist.loc[\"n=01\"]\n",
    "joint_dist.loc[\"n=11\"] = [x1**2, x2**2]\n",
    "joint_dist = joint_dist/joint_dist.sum()\n",
    "joint_dist = joint_dist*p\n",
    "display(joint_dist)\n",
    "\n",
    "Hxn_12 = joint_dist.applymap(np.log2)\n",
    "Hxn_12 = Hxn_12 * -joint_dist\n",
    "Hxn_12 = Hxn_12.sum().sum()\n",
    "print(\"H(x,n_12) = \", Hxn_12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(n_12) =  0.025196500195077687\n",
      "H(n_12) =  0.1696983742860639\n"
     ]
    }
   ],
   "source": [
    "# f) Compute the marginal, P(n_12), and use this to find H(n_12).\n",
    "\n",
    "Pn_12 = 1 - joint_dist.loc[\"n=00\"].sum()\n",
    "print(\"P(n_12) = \", Pn_12)\n",
    "_Pn_12 = 1 - Pn_12\n",
    "\n",
    "Hn_12 = -Pn_12*np.log2(Pn_12) - _Pn_12*np.log2(_Pn_12)\n",
    "print(\"H(n_12) = \", Hn_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mutual information I(x;n_12):  -0.019497176542006223\n"
     ]
    }
   ],
   "source": [
    "# g) Using these results, compute the mutual information I(x;n12).\n",
    "mutual_info_12 = Hx + Hn_12 - Hxn_12\n",
    "print(\"mutual information I(x;n_12): \", mutual_info_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "difference between mutual infos =  0.00161544554951365\n"
     ]
    }
   ],
   "source": [
    "print(\"difference between mutual infos = \",mutual_info - mutual_info_12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### h) Notice that I(x;n_12) ~= I(x;n). Comment on whether this neuron contains information about the stimulus in the timing of spikes (a “temporal code”) or only in the number of spikes (a “rate code”).\n",
    "Because the mutual information was basically the same, we can discern that whether the spike occured slightly earlier or later didn't matter, but rather the rate coding of spikes coming in.\n",
    "It is also important to note that the refresh rate for both signals is too slow for two of the same signal to occur in the time window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
